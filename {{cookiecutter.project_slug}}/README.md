# {{ cookiecutter.project_name }}

{{ cookiecutter.project_short_description }}

## ğŸ“‹ VisÃ£o Geral

Este projeto fornece uma estrutura completa para orquestraÃ§Ã£o de workflows de dados usando [Luigi](https://github.com/spotify/luigi), desenvolvido pela Spotify. Luigi permite construir pipelines de dados complexos com gerenciamento automÃ¡tico de dependÃªncias, visualizaÃ§Ã£o e monitoramento.

**Autor:** {{ cookiecutter.author_name }} <{{ cookiecutter.author_email }}>

## ğŸš€ ComeÃ§ando

### PrÃ©-requisitos

- Python {{ cookiecutter.python_version }} ou superior
- uv (gerenciador de pacotes Python) ou pip

### InstalaÃ§Ã£o

1. **Crie e ative um ambiente virtual**

```bash
# Usando uv
uv venv
source venv/bin/activate  # Linux/Mac
# venv\Scripts\activate  # Windows

# Ou usando venv
python -m venv venv
source venv/bin/activate  # Linux/Mac
# venv\Scripts\activate  # Windows
```

2. **Instale as dependÃªncias**

```bash
# Usando uv
uv sync

# Ou usando pip
pip install -e .
```

3. **Configure variÃ¡veis de ambiente**

```bash
cp .env.example .env
# Edite o .env com suas configuraÃ§Ãµes
```

4. **Configure o Luigi**

```bash
cp luigi.cfg.example luigi.cfg
# Edite luigi.cfg conforme necessÃ¡rio
```
{% if cookiecutter.include_scrapy == "y" %}
5. **Configure o Scrapy** (se estiver usando web scraping)

```bash
cp scrapy.cfg.example scrapy.cfg
```
{% endif %}

## ğŸ“ Estrutura do Projeto

```
{{ cookiecutter.project_slug }}/
â”œâ”€â”€ src/{{ cookiecutter.project_slug }}/
â”‚   â”œâ”€â”€ tasks/              # Luigi tasks
â”‚   â”‚   â”œâ”€â”€ core/           # Core task base classes
â”‚   â”‚   â””â”€â”€ ...
{% if cookiecutter.include_scrapy == "y" %}â”‚   â”œâ”€â”€ spiders/            # Scrapy spiders
â”‚   â”œâ”€â”€ scrapers/           # Custom scrapers
{% endif %}{% if cookiecutter.include_scheduler == "y" %}â”‚   â”œâ”€â”€ scheduler/          # Task scheduling
{% endif %}{% if cookiecutter.include_fastapi == "y" %}â”‚   â”œâ”€â”€ api/                # FastAPI endpoints
{% endif %}â”‚   â”œâ”€â”€ utils/              # Utility functions
â”‚   â””â”€â”€ settings.py         # Configuration
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                # Raw data
â”‚   â”œâ”€â”€ processed/          # Processed data
â”‚   â””â”€â”€ outputs/            # Final outputs
â”œâ”€â”€ tests/                  # Unit tests
â”œâ”€â”€ logs/                   # Application logs
â”œâ”€â”€ pyproject.toml          # Project configuration
{% if cookiecutter.include_scrapy == "y" %}â”œâ”€â”€ scrapy.cfg              # Scrapy configuration
{% endif %}â””â”€â”€ README.md               # This file
```

## ğŸƒ Executando o Projeto

### Rodar uma task Luigi

```bash
# Com scheduler local
luigi --module {{ cookiecutter.project_slug }}.tasks ExampleTask --local-scheduler

# Com scheduler central
luigid --port 8082  # Em um terminal
luigi --module {{ cookiecutter.project_slug }}.tasks ExampleTask  # Em outro terminal
```
{% if cookiecutter.include_scheduler == "y" %}
### Iniciar o Scheduler Customizado

```bash
python -m {{ cookiecutter.project_slug }}.scheduler
```
{% endif %}{% if cookiecutter.include_scrapy == "y" %}
### Rodar Scrapy Spiders

```bash
scrapy crawl spider_name
```
{% endif %}{% if cookiecutter.include_fastapi == "y" %}
### Iniciar o Servidor API

```bash
uvicorn {{ cookiecutter.project_slug }}.api.serve:app --reload
```

API disponÃ­vel em: http://localhost:8000
DocumentaÃ§Ã£o: http://localhost:8000/docs
{% endif %}

## ğŸ§ª Testes

Execute os testes com pytest:

```bash
pytest tests/ -v
```

Com cobertura:

```bash
pytest tests/ --cov={{ cookiecutter.project_slug }} --cov-report=html
```

## ğŸ“ Desenvolvimento

### Criar Nova Task

Crie um arquivo em `src/{{ cookiecutter.project_slug }}/tasks/` seguindo o padrÃ£o:

```python
import luigi
from datetime import datetime
from {{ cookiecutter.project_slug }}.settings import PROCESSED_DATA_PATH

class MyTask(luigi.Task):
    date = luigi.DateParameter(default=datetime.now().date())
    
    def output(self):
        return luigi.LocalTarget(PROCESSED_DATA_PATH / f"my_task_{self.date}.csv")
    
    def run(self):
        # Sua lÃ³gica aqui
        pass
```
{% if cookiecutter.include_scrapy == "y" %}
### Criar Novo Spider

```bash
scrapy genspider spider_name domain.com
```

Ou crie manualmente em `src/{{ cookiecutter.project_slug }}/spiders/`.
{% endif %}

## ğŸ”§ ConfiguraÃ§Ã£o

### Luigi Configuration (luigi.cfg)

Configure workers, retries, logging e outros parÃ¢metros do Luigi.

### Environment Variables (.env)

Defina API keys, database URLs e outras configuraÃ§Ãµes sensÃ­veis.

### Settings (src/{{ cookiecutter.project_slug }}/settings.py)

Configure paths de dados, configuraÃ§Ãµes do Scrapy e outras constantes do projeto.

## ğŸ“š Recursos

- [Luigi Documentation](https://luigi.readthedocs.io/)
{% if cookiecutter.include_scrapy == "y" %}- [Scrapy Documentation](https://docs.scrapy.org/)
{% endif %}{% if cookiecutter.include_fastapi == "y" %}- [FastAPI Documentation](https://fastapi.tiangolo.com/)
{% endif %}- [Python Best Practices](https://docs.python-guide.org/)

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ licenciado sob a licenÃ§a {{ cookiecutter.open_source_license }} - veja o arquivo LICENSE para detalhes.

## âœ¨ Contribuindo

ContribuiÃ§Ãµes sÃ£o bem-vindas! Por favor:

1. FaÃ§a um fork do projeto
2. Crie uma branch para sua feature (`git checkout -b feature/AmazingFeature`)
3. Commit suas mudanÃ§as (`git commit -m 'Add some AmazingFeature'`)
4. Push para a branch (`git push origin feature/AmazingFeature`)
5. Abra um Pull Request

## ğŸ“§ Contato

{{ cookiecutter.author_name }} - {{ cookiecutter.author_email }}

---

Gerado com â¤ï¸ usando [Cookiecutter](https://github.com/cookiecutter/cookiecutter)
